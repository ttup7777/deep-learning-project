{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import defaultdict","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\ntest = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8ec63c9c73ea76520ef2902864565a36c0b4f0ad"},"cell_type":"code","source":"emoji_dict = defaultdict()\nwith open('../input/emoji-unicode-names/emoji_unicode_names_final.txt', 'r', encoding=\"utf8\") as f:\n    lines = f.readlines()\n    for line in lines:\n        tokens = line.strip().split('\\t')\n        emoji_dict[tokens[0]] = tokens[1]","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b964ed8cb4f6a49bb9e2cd121b06257a522e15b8"},"cell_type":"code","source":"# here is the sample emoji list..\nfor i in emoji_dict:\n    if \"face\" in emoji_dict[i] or \"eyes\" in emoji_dict[i]:\n        print(i , \" : \", emoji_dict[i])","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"69363dae2f3d57ba5391e4f023783b75b8efac46"},"cell_type":"markdown","source":"This not just classify \"good\" or \"bad\" emoji. It also \"**describe**\" emoji. Which we can split by \"_\" and apply word2vec or GloVe to classify emojis. \n\nLike \"üòï : confounded_face\" is hard to classify as bad or good. But GloVe can tell much more about \"words\" rather than an  \"emoji\" !!\n\nDetailed description is given. \n\nLike \"üòç  :  smiling_face_with_heart_shaped_eyes\". \nWe can use it very efficiently.\nother examples : \n\nüòá  :  smiling_face_with_halo\n\nüòà  :  smiling_face_with_horns\n(see the detailed difference..)\n\nhere is the complete dataset : https://www.kaggle.com/prashantkikani/emoji-unicode-names\n\nPlease do contribute if you find any other things that can be done with above dataset."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"fa08f3c966326d2edb8576845f3a9c18175854b1"},"cell_type":"code","source":"repl = {\n    \"&lt;3\": \" good \",\n    \":d\": \" good \",\n    \":dd\": \" good \",\n    \":p\": \" good \",\n    \"8)\": \" good \",\n    \":-)\": \" good \",\n    \":)\": \" good \",\n    \";)\": \" good \",\n    \"(-:\": \" good \",\n    \"(:\": \" good \",\n    \"yay!\": \" good \",\n    \"yay\": \" good \",\n    \"yaay\": \" good \",\n    \"yaaay\": \" good \",\n    \"yaaaay\": \" good \",\n    \"yaaaaay\": \" good \",\n    \":/\": \" bad \",\n    \":&gt;\": \" sad \",\n    \":')\": \" sad \",\n    \":-(\": \" bad \",\n    \":(\": \" bad \",\n    \":s\": \" bad \",\n    \":-s\": \" bad \",\n    \"&lt;3\": \" heart \",\n    \":d\": \" smile \",\n    \":p\": \" smile \",\n    \":dd\": \" smile \",\n    \"8)\": \" smile \",\n    \":-)\": \" smile \",\n    \":)\": \" smile \",\n    \";)\": \" smile \",\n    \"(-:\": \" smile \",\n    \"(:\": \" smile \",\n    \":/\": \" worry \",\n    \":&gt;\": \" angry \",\n    \":')\": \" sad \",\n    \":-(\": \" sad \",\n    \":(\": \" sad \",\n    \":s\": \" sad \",\n    \":-s\": \" sad \",\n    r\"\\br\\b\": \"are\",\n    r\"\\bu\\b\": \"you\",\n    r\"\\bhaha\\b\": \"ha\",\n    r\"\\bhahaha\\b\": \"ha\",\n    r\"\\bdon't\\b\": \"do not\",\n    r\"\\bdoesn't\\b\": \"does not\",\n    r\"\\bdidn't\\b\": \"did not\",\n    r\"\\bhasn't\\b\": \"has not\",\n    r\"\\bhaven't\\b\": \"have not\",\n    r\"\\bhadn't\\b\": \"had not\",\n    r\"\\bwon't\\b\": \"will not\",\n    r\"\\bwouldn't\\b\": \"would not\",\n    r\"\\bcan't\\b\": \"can not\",\n    r\"\\bcannot\\b\": \"can not\",\n    r\"\\bi'm\\b\": \"i am\",\n    \"m\": \"am\",\n    \"r\": \"are\",\n    \"u\": \"you\",\n    \"haha\": \"ha\",\n    \"hahaha\": \"ha\",\n    \"don't\": \"do not\",\n    \"doesn't\": \"does not\",\n    \"didn't\": \"did not\",\n    \"hasn't\": \"has not\",\n    \"haven't\": \"have not\",\n    \"hadn't\": \"had not\",\n    \"won't\": \"will not\",\n    \"wouldn't\": \"would not\",\n    \"can't\": \"can not\",\n    \"cannot\": \"can not\",\n    \"i'm\": \"i am\",\n    \"m\": \"am\",\n    \"i'll\" : \"i will\",\n    \"its\" : \"it is\",\n    \"it's\" : \"it is\",\n    \"'s\" : \" is\",\n    \"that's\" : \"that is\",\n    \"weren't\" : \"were not\",\n}\nkeys = [i for i in repl.keys()]","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7add18783b87fdc9f625974d157a06b47418cf8"},"cell_type":"code","source":"new_train_data = []\nnew_test_data = []\nc_train = 0\nc_test = 0\nltr = train[\"comment_text\"].tolist()\nlte = test[\"comment_text\"].tolist()\nfor i in ltr:\n    arr = str(i).split()\n    xx = \"\"\n    for j in arr:\n        j = str(j).lower()\n        if j[:4] == 'http' or j[:3] == 'www':\n            # c_train += 1\n            continue\n        if j in keys:\n            # print(\"inn\")\n            c_train += 1\n            j = repl[j]\n        if j in emoji_dict:\n            c_train += 1\n            j = emoji_dict[j]\n        xx += j + \" \"\n    new_train_data.append(xx)\nfor i in lte:\n    arr = str(i).split()\n    xx = \"\"\n    for j in arr:\n        j = str(j).lower()\n        if j[:4] == 'http' or j[:3] == 'www':\n            # c_test += 1\n            continue\n        if j in keys:\n            # print(\"inn\")\n            c_test += 1\n            j = repl[j]\n        if j in emoji_dict:\n            c_test += 1\n            j = emoji_dict[j]\n        xx += j + \" \"\n    new_test_data.append(xx)\ntrain[\"new_comment_text\"] = new_train_data\ntest[\"new_comment_text\"] = new_test_data\n\nprint(\"replacements in train data : \", c_train)\nprint(\"replacements in test data : \", c_test)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"712b3b1613bb079f7957bc0589871c500f866b2e"},"cell_type":"markdown","source":"So, 111297 replacements in train data & 101419 in test data. Super cool !!\n\nImprove your models with this emoji map."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}